{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \".\"\n",
    "\n",
    "training_folder = 'D:/Dataset/aidea-farmland-crops-autumn/train'\n",
    "\n",
    "public_folder = 'D:/Dataset/aidea-farmland-crops-autumn/public'\n",
    "\n",
    "private_folder = 'D:/Dataset/aidea-farmland-crops-autumn/private'\n",
    "\n",
    "labels = next(os.walk(training_folder), (None, None, []))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: PIL will automatically correct the width and height according to EXIF (angle)\n",
    "def get_image_information_without_loading(path, folder=None, limit=None):\n",
    "    data = {key: [] for key in ['file', 'label', 'shape', 'height', 'width', 'taken_datetime', 'make', 'model', 'angle']}\n",
    "    for file in os.listdir(path)[:limit]:\n",
    "        filedir = F'{path}/{file}'\n",
    "        image = Image.open(filedir)\n",
    "        data['file'].append(file)\n",
    "        data['label'].append(folder)\n",
    "        data['shape'].append(image.size)\n",
    "        data['width'].append(image.size[0])\n",
    "        data['height'].append(image.size[1])\n",
    "        # check image._getexif is not NoneType and has key 36867\n",
    "        data['taken_datetime'].append(pd.to_datetime(image._getexif()[36867], format=\"%Y:%m:%d %H:%M:%S\") if \n",
    "            (image._getexif() is not None and 36867 in image._getexif()) else None)\n",
    "        # check image._getexif is not NoneType and has key 271\n",
    "        data['make'].append(image._getexif()[271] if \n",
    "            (image._getexif() is not None and 271 in image._getexif()) else None)\n",
    "        # check image._getexif is not NoneType and has key 272\n",
    "        data['model'].append(image._getexif()[272] if \n",
    "            (image._getexif() is not None and 272 in image._getexif()) else None)\n",
    "        # check image._getexif is not NoneType and has key 274\n",
    "        data['angle'].append(image._getexif()[274] if (image._getexif() is not None and 274 in image._getexif()) else None)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Note: go_through_folders\n",
    "def go_through_folders_to_get_image_information(path, limit=None, verbose=0):\n",
    "    files, folders = [], []\n",
    "    data = pd.DataFrame()\n",
    "    for (dirpath, foldernames, filenames) in os.walk(path):\n",
    "        folders.extend(foldernames), files.extend(filenames)\n",
    "        break\n",
    "    for idx, folder in enumerate(folders):\n",
    "        folderdir = F'{path}/{folder}'\n",
    "        if(verbose):\n",
    "            print(F'{idx+1}/{len(folders)}, folderdir: {folderdir}')\n",
    "        current = get_image_information_without_loading(folderdir, folder, limit=limit)\n",
    "        data = pd.concat([data, current])\n",
    "    return data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angle_from_exif(path):\n",
    "    image = Image.open(path)\n",
    "    angle = image._getexif()[274] if (image._getexif() is not None and 274 in image._getexif()) else None\n",
    "    return angle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Image and EXIF\n",
    "讀取圖片的基本資料，需要注意並非每張圖片都有 EXIF 資訊"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tag_loc_coor = pd.read_csv(F'{path}/data/train_tag_loc_coor.csv')\n",
    "train_describe = go_through_folders_to_get_image_information(training_folder, limit=5, verbose=1)\n",
    "# Get Datetime from EXIF\n",
    "train_describe['taken_month'] = pd.to_datetime(train_describe['taken_datetime']).dt.month\n",
    "train_describe['taken_year'] = pd.to_datetime(train_describe['taken_datetime']).dt.year\n",
    "train_describe['taken_hour'] = pd.to_datetime(train_describe['taken_datetime']).dt.hour\n",
    "# Get Angle from EXIF\n",
    "train_describe['angle'] = train_describe['angle'].apply(lambda x: {1:0, 3:180, 6:270, 8:90}[x] if x in [1, 3, 6, 8] else x)\n",
    "train_describe = pd.merge(train_describe, train_tag_loc_coor, on='file')\n",
    "train_describe.to_csv(F'{path}/train_tag_loc_coor_describe.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taken_month</th>\n",
       "      <th>taken_year</th>\n",
       "      <th>taken_hour</th>\n",
       "      <th>target_fid</th>\n",
       "      <th>target_x</th>\n",
       "      <th>target_y</th>\n",
       "      <th>town_x</th>\n",
       "      <th>town_y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>55096.000000</td>\n",
       "      <td>55096.000000</td>\n",
       "      <td>55096.000000</td>\n",
       "      <td>89514.000000</td>\n",
       "      <td>89514.000000</td>\n",
       "      <td>89514.000000</td>\n",
       "      <td>89514.000000</td>\n",
       "      <td>89514.000000</td>\n",
       "      <td>89514.000000</td>\n",
       "      <td>89514.000000</td>\n",
       "      <td>84356.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.317174</td>\n",
       "      <td>2019.442428</td>\n",
       "      <td>12.252940</td>\n",
       "      <td>44756.500000</td>\n",
       "      <td>0.650770</td>\n",
       "      <td>-33.431352</td>\n",
       "      <td>120.563448</td>\n",
       "      <td>23.622252</td>\n",
       "      <td>2783.064236</td>\n",
       "      <td>3355.647094</td>\n",
       "      <td>75.447390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.112334</td>\n",
       "      <td>0.550250</td>\n",
       "      <td>3.143825</td>\n",
       "      <td>25840.610335</td>\n",
       "      <td>22.651154</td>\n",
       "      <td>92.331170</td>\n",
       "      <td>0.289508</td>\n",
       "      <td>0.576954</td>\n",
       "      <td>1026.272960</td>\n",
       "      <td>1464.427506</td>\n",
       "      <td>121.155522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1462.000000</td>\n",
       "      <td>-2683.000000</td>\n",
       "      <td>120.099205</td>\n",
       "      <td>22.049339</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>22378.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.364716</td>\n",
       "      <td>23.404182</td>\n",
       "      <td>1633.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>44756.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.483185</td>\n",
       "      <td>23.778591</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>67134.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.665039</td>\n",
       "      <td>23.955526</td>\n",
       "      <td>3120.000000</td>\n",
       "      <td>4208.000000</td>\n",
       "      <td>270.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>89513.000000</td>\n",
       "      <td>1004.000000</td>\n",
       "      <td>2043.000000</td>\n",
       "      <td>121.760269</td>\n",
       "      <td>25.083782</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>270.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        taken_month    taken_year    taken_hour    target_fid      target_x  \\\n",
       "count  55096.000000  55096.000000  55096.000000  89514.000000  89514.000000   \n",
       "mean       7.317174   2019.442428     12.252940  44756.500000      0.650770   \n",
       "std        3.112334      0.550250      3.143825  25840.610335     22.651154   \n",
       "min        1.000000   2019.000000      4.000000      0.000000  -1462.000000   \n",
       "25%        4.000000   2019.000000     10.000000  22378.250000      0.000000   \n",
       "50%        9.000000   2019.000000     12.000000  44756.500000      0.000000   \n",
       "75%       10.000000   2020.000000     15.000000  67134.750000      0.000000   \n",
       "max       12.000000   2022.000000     20.000000  89513.000000   1004.000000   \n",
       "\n",
       "           target_y        town_x        town_y         width        height  \\\n",
       "count  89514.000000  89514.000000  89514.000000  89514.000000  89514.000000   \n",
       "mean     -33.431352    120.563448     23.622252   2783.064236   3355.647094   \n",
       "std       92.331170      0.289508      0.576954   1026.272960   1464.427506   \n",
       "min    -2683.000000    120.099205     22.049339    750.000000    640.000000   \n",
       "25%        0.000000    120.364716     23.404182   1633.000000   1600.000000   \n",
       "50%        0.000000    120.483185     23.778591   3000.000000   4000.000000   \n",
       "75%        0.000000    120.665039     23.955526   3120.000000   4208.000000   \n",
       "max     2043.000000    121.760269     25.083782   8000.000000   8000.000000   \n",
       "\n",
       "              angle  \n",
       "count  84356.000000  \n",
       "mean      75.447390  \n",
       "std      121.155522  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%      270.000000  \n",
       "max      270.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_describe = pd.read_csv(F'{path}/data/train_tag_loc_coor_describe.csv')\n",
    "train_describe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Takens: 34418 (38.45%)\n"
     ]
    }
   ],
   "source": [
    "# Check how much data has exif\n",
    "invalid_takens = train_describe[(train_describe['taken_datetime'].isnull())]\n",
    "print(F'Invalid Takens: {len(invalid_takens)} ({len(invalid_takens)/len(train_describe)*100:.2f}%)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_tag_loc_coor = pd.read_csv(F'{path}/data/public_tag_loc_coor.csv')\n",
    "public_describe = get_image_information_without_loading(private_folder)\n",
    "# Get Angle from EXIF\n",
    "public_describe['angle'] = public_describe['angle'].apply(lambda x: {1:0, 3:180, 6:270, 8:90}[x] if x in [1, 3, 6, 8] else x)\n",
    "public_describe = pd.merge(public_describe, public_tag_loc_coor, on='file')\n",
    "public_describe.to_csv(F'{path}/data/public_tag_loc_coor_describe.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_tag_loc_coor = pd.read_csv(F'{path}/data/private_tag_loc_coor.csv')\n",
    "private_describe = get_image_information_without_loading(private_folder)\n",
    "# Get Angle from EXIF\n",
    "private_describe['angle'] = private_describe['angle'].apply(lambda x: {1:0, 3:180, 6:270, 8:90}[x] if x in [1, 3, 6, 8] else x)\n",
    "private_describe = pd.merge(private_describe, private_tag_loc_coor, on='file')\n",
    "private_describe.to_csv(F'{path}/data/private_tag_loc_coor_describe.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Takens: 4300 (38.53%)\n"
     ]
    }
   ],
   "source": [
    "# Check how much data has exif\n",
    "invalid_takens = private_describe[(private_describe['taken_datetime'].isnull())]\n",
    "print(F'Invalid Takens: {len(invalid_takens)} ({len(invalid_takens)/len(private_describe)*100:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_fid            0\n",
       "file                  0\n",
       "target_x              0\n",
       "target_y              0\n",
       "county_name           0\n",
       "town_name             0\n",
       "town_x                0\n",
       "town_y                0\n",
       "label             11160\n",
       "shape                 0\n",
       "height                0\n",
       "width                 0\n",
       "taken_datetime     4300\n",
       "make               4206\n",
       "model              4206\n",
       "angle               734\n",
       "taken_month        4300\n",
       "taken_year         4300\n",
       "taken_hour         4300\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# private_tag_loc_coor = pd.read_csv(F'{path}/data/private_tag_loc_coor.csv')\n",
    "# private = pd.merge(private_tag_loc_coor, private, on='file')\n",
    "# private.to_csv(F'{path}/data/private_tag_loc_coor_describe.csv', index=False)\n",
    "private = pd.read_csv(F'{path}/data/private_tag_loc_coor_describe.csv')\n",
    "private.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Elevation of Towns\n",
    "取得各個鄉鎮的海拔資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script for returning elevation from lat, long, based on open elevation data, which in turn is based on SRTM\n",
    "def get_elevation(lat, long):\n",
    "    query = ('https://api.open-elevation.com/api/v1/lookup'\n",
    "             f'?locations={lat},{long}')\n",
    "    r = requests.get(query).json()  # json object, various ways you can extract value\n",
    "    # one approach is to use pandas json functionality:\n",
    "    elevation = pd.json_normalize(r, 'results')['elevation'].values[0]\n",
    "    return elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_by_town_x_y = train_describe.groupby(['county_name', 'town_name', 'town_x', 'town_y']).size().reset_index(name='counts')\n",
    "group_by_town_x_y = group_by_town_x_y.sort_values(by=['counts'], inplace=False).reset_index(drop=True)\n",
    "len(group_by_town_x_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_town_x_y['town_z'] = group_by_town_x_y.apply(lambda row: get_elevation(row['town_y'], row['town_x']), axis=1)\n",
    "group_by_town_x_y.to_csv(F'{path}/data/train_groupby_town_elevation.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Elevation to Dataset\n",
    "將海拔資訊加入到資料集中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elevation_from_dataframe_by_county_town(df, county_name, town_name):\n",
    "    df = df[df['county_name'].eq(county_name)]\n",
    "    df = df[df['town_name'].eq(town_name)]\n",
    "    return df['town_z'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_town_x_y = pd.read_csv(F'{path}/data/train_groupby_town_elevation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_describe['town_z'] = train_describe.apply(lambda row: get_elevation_from_dataframe_by_county_town(group_by_town_x_y, row['county_name'], row['town_name']), axis=1)\n",
    "train_describe.to_csv(F'{path}/data/train_tag_loc_coor_describe_elevation.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_describe['town_z'] = public_describe.apply(lambda row: get_elevation_from_dataframe_by_county_town(group_by_town_x_y, row['county_name'], row['town_name']), axis=1)\n",
    "public_describe.to_csv(F'{path}/data/public_tag_loc_coor_describe_elevation.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_describe['town_z'] = private_describe.apply(lambda row: get_elevation_from_dataframe_by_county_town(group_by_town_x_y, row['county_name'], row['town_name']), axis=1)\n",
    "private_describe.to_csv(F'{path}/data/private_tag_loc_coor_describe_elevation.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1fe34f43cecd3b1506669e990de3780e558c5eb6715cb313146f8f61288c7aab"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorflow-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
